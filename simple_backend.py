#!/usr/bin/env python3
"""ä¿®å¾©ç‰ˆå¾Œç«¯æœå‹™"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional
import json
import os
import logging
import ollama
import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer
import uuid

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å‰µå»º FastAPI æ‡‰ç”¨
app = FastAPI(
    title="æ™ºæ…§å‹ç½ä¿éšªä¸€ç«™å¼æœå‹™",
    description="æä¾›å‹ç½ä¿éšªè«®è©¢ã€åœ°åœ–æœç´¢å’Œå¤±èƒ½çµ¦ä»˜æŸ¥è©¢æœå‹™",
    version="1.0.0"
)

# CORS è¨­ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:61269", "http://127.0.0.1:3000", "http://127.0.0.1:61269"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# é è¨­å•é¡Œå’Œå›ºå®šç­”æ¡ˆ
PRESET_QA = {
    "ä»€éº¼æ˜¯å‹å·¥ä¿éšª": "å‹å·¥ä¿éšªæ˜¯æ”¿åºœè¨­ç«‹çš„ç¤¾æœƒä¿éšªåˆ¶åº¦ï¼Œä¿éšœå‹å·¥åœ¨ç”Ÿç—…ã€å‚·ç—…ã€ç”Ÿè‚²ã€è·ç½ç­‰æƒ…æ³ä¸‹çš„é†«ç™‚ã€æ’«å¹ç­‰ä¿éšœã€‚",
    "å‹å·¥ä¿éšªå¤±èƒ½çµ¦ä»˜": "å¤±èƒ½çµ¦ä»˜åˆ†15ç´šï¼ŒæŒ‰å¹³å‡æ—¥æŠ•ä¿è–ªè³‡Ã—æ—¥æ•¸è¨ˆç®—ã€‚ç¬¬1ç´š1200æ—¥ï¼Œç¬¬15ç´š30æ—¥ã€‚",
    "å¦‚ä½•ç”³è«‹å¤±èƒ½çµ¦ä»˜": "1.æº–å‚™å¤±èƒ½è¨ºæ–·æ›¸ 2.å¡«å¯«ç”³è«‹æ›¸ 3.å‘å‹ä¿å±€ç”³è«‹ 4.ç­‰å¾…å¯©æ ¸çµæœã€‚",
    "å¤±èƒ½ç­‰ç´šå¦‚ä½•åˆ¤å®š": "ç”±å¥ä¿ç‰¹ç´„é†«é™¢æˆ–è¨ºæ‰€å‡ºå…·å¤±èƒ½è¨ºæ–·æ›¸ï¼Œä¾å‹å·¥ä¿éšªå¤±èƒ½çµ¦ä»˜æ¨™æº–åˆ¤å®šç­‰ç´šã€‚",
    "å¤±èƒ½çµ¦ä»˜é‡‘é¡": "æ™®é€šå‚·ç—…ï¼šç¬¬1ç´š1200æ—¥ï¼Œç¬¬15ç´š30æ—¥ã€‚è·æ¥­å‚·ç—…ï¼šç¬¬1ç´š1800æ—¥ï¼Œç¬¬15ç´š45æ—¥ã€‚",
    "ç”³è«‹å¤±èƒ½çµ¦ä»˜éœ€è¦ä»€éº¼æ–‡ä»¶": "å¤±èƒ½è¨ºæ–·æ›¸ã€ç”³è«‹æ›¸ã€èº«åˆ†è­‰æ˜ã€æŠ•ä¿è³‡æ–™ç­‰ç›¸é—œæ–‡ä»¶ã€‚",
    "å¤±èƒ½çµ¦ä»˜å¤šä¹…å¯ä»¥é ˜åˆ°": "ç”³è«‹å¾Œç´„1-2å€‹æœˆå…§å¯©æ ¸å®Œæˆï¼Œé€šéå¾Œå³å¯é ˜å–çµ¦ä»˜ã€‚",
    "å¤±èƒ½çµ¦ä»˜å¯ä»¥é ˜å¹¾æ¬¡": "å¤±èƒ½çµ¦ä»˜ç‚ºä¸€æ¬¡çµ¦ä»˜ï¼Œé ˜å–å¾Œå³çµæ¡ˆã€‚",
    "ä»€éº¼æ˜¯è·æ¥­å‚·ç—…": "å› åŸ·è¡Œè·å‹™è€Œè‡´å‚·å®³æˆ–ç–¾ç—…ï¼ŒåŒ…æ‹¬è·æ¥­ç½å®³å’Œè·æ¥­ç—…ã€‚",
    "è·æ¥­å‚·ç—…çµ¦ä»˜æ¨™æº–": "è·æ¥­å‚·ç—…å¤±èƒ½çµ¦ä»˜æ¯”æ™®é€šå‚·ç—…é«˜1.5å€ï¼Œå¦‚ç¬¬1ç´š1800æ—¥ã€‚",
    "å¤±èƒ½è¨ºæ–·æ›¸å“ªè£¡é–‹": "å¥ä¿ç‰¹ç´„é†«é™¢æˆ–è¨ºæ‰€ï¼Œéƒ¨åˆ†é …ç›®éœ€é†«å­¸ä¸­å¿ƒæˆ–å€åŸŸé†«é™¢ä»¥ä¸Šã€‚",
    "å¤±èƒ½çµ¦ä»˜ç”³è«‹è³‡æ ¼": "å‹ä¿è¢«ä¿éšªäººï¼Œç¶“æ²»ç™‚å¾Œç—‡ç‹€å›ºå®šï¼Œå†è¡Œæ²»ç™‚ä»ä¸èƒ½æœŸå¾…å…¶æ²»ç™‚æ•ˆæœè€…ã€‚",
    "å¤±èƒ½çµ¦ä»˜è¨ˆç®—æ–¹å¼": "å¹³å‡æ—¥æŠ•ä¿è–ªè³‡ Ã— å¤±èƒ½ç­‰ç´šå°æ‡‰æ—¥æ•¸ = çµ¦ä»˜é‡‘é¡ã€‚",
    "å¤±èƒ½çµ¦ä»˜å…ç¨…å—": "å¤±èƒ½çµ¦ä»˜å…ç´æ‰€å¾—ç¨…ï¼Œä½†éœ€ä¾è¦å®šç”³å ±ã€‚",
    "å¤±èƒ½çµ¦ä»˜å¯ä»¥åˆ†æœŸé ˜å–å—": "å¤±èƒ½çµ¦ä»˜ç‚ºä¸€æ¬¡çµ¦ä»˜ï¼Œç„¡æ³•åˆ†æœŸé ˜å–ã€‚",
    "å¤±èƒ½ç­‰ç´šå¦‚ä½•è©•ä¼°": "å¤±èƒ½ç­‰ç´šè©•ä¼°ä¾æ“šå¤±èƒ½ç¨‹åº¦ã€åº·å¾©å¯èƒ½æ€§ã€ä»¥åŠå°ç”Ÿæ´»åŠŸèƒ½é€ æˆçš„å½±éŸ¿ã€‚ç”±å¥ä¿ç‰¹ç´„é†«é™¢å‡ºå…·å¤±èƒ½è¨ºæ–·æ›¸ï¼Œä¾å‹å·¥ä¿éšªå¤±èƒ½çµ¦ä»˜æ¨™æº–åˆ¤å®šç­‰ç´šï¼Œåˆ†ç‚º15ç´šï¼Œç¬¬1ç´šæœ€åš´é‡ï¼ˆ1200æ—¥ï¼‰ï¼Œç¬¬15ç´šæœ€è¼•å¾®ï¼ˆ30æ—¥ï¼‰ã€‚è©•ä¼°æ™‚æœƒè€ƒæ…®èº«é«”æ©Ÿèƒ½ã€å·¥ä½œèƒ½åŠ›ã€æ—¥å¸¸ç”Ÿæ´»è‡ªç†èƒ½åŠ›ç­‰å› ç´ ã€‚"
}

# è¼‰å…¥å¸¸è¦‹å•é¡Œè³‡æ–™åº«
def load_qa_database():
    """è¼‰å…¥å¸¸è¦‹å•é¡Œè³‡æ–™åº«"""
    try:
        with open('å¸¸è¦‹å•é¡Œè³‡æ–™åº«.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        logger.warning("å¸¸è¦‹å•é¡Œè³‡æ–™åº«æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é è¨­å•é¡Œ")
        return None
    except Exception as e:
        logger.error(f"è¼‰å…¥å¸¸è¦‹å•é¡Œè³‡æ–™åº«å¤±æ•—: {e}")
        return None

# è¼‰å…¥å¸¸è¦‹å•é¡Œè³‡æ–™åº«
qa_database = load_qa_database()

# åˆå§‹åŒ– ChromaDB å’Œ Sentence Transformer
try:
    # åˆå§‹åŒ– ChromaDB
    chroma_client = chromadb.Client(Settings(
        persist_directory="./chroma_db",
        anonymized_telemetry=False
    ))
    
    # åˆå§‹åŒ– Sentence Transformer (ä½¿ç”¨ä¸­æ–‡æ¨¡å‹)
    embedding_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
    
    # å‰µå»ºæˆ–ç²å–é›†åˆ
    collection = chroma_client.get_or_create_collection(
        name="labor_insurance_knowledge",
        metadata={"description": "å‹å·¥ä¿éšªçŸ¥è­˜åº«"}
    )
    
    logger.info("ChromaDB å’Œ Sentence Transformer åˆå§‹åŒ–æˆåŠŸ")
except Exception as e:
    logger.error(f"åˆå§‹åŒ– ChromaDB å¤±æ•—: {e}")
    chroma_client = None
    embedding_model = None
    collection = None

# è¼‰å…¥æ‰€æœ‰å‹ä¿è³‡æ–™é›†åˆ°å‘é‡æ•¸æ“šåº«
def load_all_datasets_to_vector_db():
    """è¼‰å…¥æ‰€æœ‰å‹ä¿è³‡æ–™é›†åˆ°å‘é‡æ•¸æ“šåº«"""
    if not collection or not embedding_model:
        logger.warning("ChromaDB æˆ– embedding_model æœªåˆå§‹åŒ–ï¼Œè·³éå‘é‡æ•¸æ“šåº«è¼‰å…¥")
        return False
    
    try:
        # æª¢æŸ¥æ˜¯å¦å·²ç¶“æœ‰æ•¸æ“š
        existing_count = collection.count()
        if existing_count > 0:
            logger.info(f"å‘é‡æ•¸æ“šåº«å·²æœ‰ {existing_count} æ¢è¨˜éŒ„ï¼Œè·³éé‡æ–°è¼‰å…¥")
            return True
        
        documents = []
        metadatas = []
        ids = []
        
        # 1. è¼‰å…¥å¤±èƒ½çµ¦ä»˜æ¨™æº–ç¬¬ä¸‰æ¢é™„è¡¨
        try:
            with open('å‹ä¿è³‡æ–™é›†/å‹å·¥ä¿éšªå¤±èƒ½çµ¦ä»˜æ¨™æº–ç¬¬ä¸‰æ¢é™„è¡¨.json', 'r', encoding='utf-8') as f:
                disability_standards = json.load(f)
            
            for item in disability_standards:
                doc_text = f"""
å¤±èƒ½ç¨®é¡ï¼š{item.get('å¤±èƒ½ç¨®é¡', '')}
å¤±èƒ½é …ç›®ï¼š{item.get('å¤±èƒ½é …ç›®', '')}
å¤±èƒ½ç‹€æ…‹ï¼š{item.get('å¤±èƒ½ç‹€æ…‹', '')}
å¤±èƒ½ç­‰ç´šï¼š{item.get('å¤±èƒ½ç­‰ç´š', '')}
å¤±èƒ½å¯©æ ¸åŸºæº–ï¼š{item.get('å¤±èƒ½å¯©æ ¸åŸºæº–', '')}
é–‹å…·è¨ºæ–·æ›¸é†«ç™‚æ©Ÿæ§‹å±¤ç´šï¼š{item.get('é–‹å…·è¨ºæ–·æ›¸é†«ç™‚æ©Ÿæ§‹å±¤ç´š', '')}
                """.strip()
                
                documents.append(doc_text)
                metadatas.append({
                    "source": "å‹å·¥ä¿éšªå¤±èƒ½çµ¦ä»˜æ¨™æº–ç¬¬ä¸‰æ¢é™„è¡¨",
                    "type": "å¤±èƒ½çµ¦ä»˜æ¨™æº–",
                    "å¤±èƒ½ç­‰ç´š": item.get('å¤±èƒ½ç­‰ç´š', ''),
                    "å¤±èƒ½ç¨®é¡": item.get('å¤±èƒ½ç¨®é¡', '')
                })
                ids.append(f"disability_{item.get('ç·¨è™Ÿ', uuid.uuid4())}")
                
        except Exception as e:
            logger.error(f"è¼‰å…¥å¤±èƒ½çµ¦ä»˜æ¨™æº–å¤±æ•—: {e}")
        
        # 2. è¼‰å…¥è·æ¥­å‚·ç—…å¯©æŸ¥æº–å‰‡
        try:
            with open('å‹ä¿è³‡æ–™é›†/å‹å·¥è·æ¥­ç½å®³ä¿éšªè·æ¥­å‚·ç—…å¯©æŸ¥æº–å‰‡.json', 'r', encoding='utf-8') as f:
                occupational_rules = json.load(f)
            
            for item in occupational_rules:
                doc_text = f"""
æ¢è™Ÿï¼š{item.get('æ¢è™Ÿ', '')}
å…§å®¹ï¼š{item.get('å…§å®¹', '')}
ä¿®æ­£ç™¼å¸ƒæ—¥æœŸï¼š{item.get('ä¿®æ­£ç™¼å¸ƒæ—¥æœŸï¼ˆæ°‘åœ‹å¹´æœˆæ—¥ï¼‰', '')}
                """.strip()
                
                documents.append(doc_text)
                metadatas.append({
                    "source": "å‹å·¥è·æ¥­ç½å®³ä¿éšªè·æ¥­å‚·ç—…å¯©æŸ¥æº–å‰‡",
                    "type": "è·æ¥­å‚·ç—…å¯©æŸ¥",
                    "æ¢è™Ÿ": item.get('æ¢è™Ÿ', '')
                })
                ids.append(f"occupational_{item.get('åºè™Ÿ', uuid.uuid4())}")
                
        except Exception as e:
            logger.error(f"è¼‰å…¥è·æ¥­å‚·ç—…å¯©æŸ¥æº–å‰‡å¤±æ•—: {e}")
        
        # 3. è¼‰å…¥é†«ç™‚çµ¦ä»˜ä»‹ç´¹
        try:
            with open('å‹ä¿è³‡æ–™é›†/å‹å·¥è·æ¥­ç½å®³ä¿éšªé†«ç™‚çµ¦ä»˜ä»‹ç´¹.json', 'r', encoding='utf-8') as f:
                medical_benefits = json.load(f)
            
            for item in medical_benefits:
                doc_text = f"""
é …ç›®ï¼š{item.get('é …ç›®', '')}
èªªæ˜ï¼š{item.get('èªªæ˜', '')}
æ³•è¦ï¼š{item.get('æ³•è¦', '')}
é©ç”¨èµ·æ—¥ï¼š{item.get('é©ç”¨èµ·æ—¥ï¼ˆæ°‘åœ‹å¹´æœˆæ—¥ï¼‰', '')}
                """.strip()
                
                documents.append(doc_text)
                metadatas.append({
                    "source": "å‹å·¥è·æ¥­ç½å®³ä¿éšªé†«ç™‚çµ¦ä»˜ä»‹ç´¹",
                    "type": "é†«ç™‚çµ¦ä»˜",
                    "é …ç›®": item.get('é …ç›®', '')
                })
                ids.append(f"medical_{uuid.uuid4()}")
                
        except Exception as e:
            logger.error(f"è¼‰å…¥é†«ç™‚çµ¦ä»˜ä»‹ç´¹å¤±æ•—: {e}")
        
        # 4. è¼‰å…¥å„å¤±èƒ½ç­‰ç´šä¹‹çµ¦ä»˜æ¨™æº–
        try:
            with open('å‹ä¿è³‡æ–™é›†/å„å¤±èƒ½ç­‰ç´šä¹‹çµ¦ä»˜æ¨™æº–.json', 'r', encoding='utf-8') as f:
                benefit_standards = json.load(f)
            
            for item in benefit_standards:
                doc_text = f"""
å¤±èƒ½ç­‰ç´šï¼š{item.get('å¤±èƒ½ç­‰ç´š', '')}
æ™®é€šå‚·ç—…å¤±èƒ½è£œåŠ©è²»çµ¦ä»˜æ¨™æº–ï¼š{item.get('æ™®é€šå‚·ç—…å¤±èƒ½è£œåŠ©è²»çµ¦ä»˜æ¨™æº–', '')}
è·æ¥­å‚·ç—…å¤±èƒ½è£œå„Ÿè²»çµ¦ä»˜æ¨™æº–ï¼š{item.get('è·æ¥­å‚·ç—…å¤±èƒ½è£œå„Ÿè²»çµ¦ä»˜æ¨™æº–', '')}
                """.strip()
                
                documents.append(doc_text)
                metadatas.append({
                    "source": "å„å¤±èƒ½ç­‰ç´šä¹‹çµ¦ä»˜æ¨™æº–",
                    "type": "çµ¦ä»˜æ¨™æº–",
                    "å¤±èƒ½ç­‰ç´š": item.get('å¤±èƒ½ç­‰ç´š', '')
                })
                ids.append(f"benefit_{item.get('å¤±èƒ½ç­‰ç´š', uuid.uuid4())}")
                
        except Exception as e:
            logger.error(f"è¼‰å…¥çµ¦ä»˜æ¨™æº–å¤±æ•—: {e}")
        
        # 5. è¼‰å…¥å‹ä¿å±€è¾¦äº‹è™•è³‡æ–™
        try:
            with open('å‹ä¿è³‡æ–™é›†/å‹ä¿å±€å„åœ°è¾¦äº‹è™•.json', 'r', encoding='utf-8') as f:
                labor_offices = json.load(f)
            
            for item in labor_offices:
                doc_text = f"""
ç¸£å¸‚åˆ¥ï¼š{item.get('ç¸£å¸‚åˆ¥', '')}
è¾¦äº‹è™•åœ°å€ï¼š{item.get('è¾¦äº‹è™•åœ°å€', '')}
è¾¦äº‹è™•é›»è©±ï¼š{item.get('è¾¦äº‹è™•é›»è©±', '')}
æ«ƒå°æœå‹™æ™‚é–“ï¼š{item.get('æ«ƒå°æœå‹™æ™‚é–“', '')}
é›»è©±æœå‹™æ™‚é–“ï¼š{item.get('é›»è©±æœå‹™æ™‚é–“', '')}
                """.strip()
                
                documents.append(doc_text)
                metadatas.append({
                    "source": "å‹ä¿å±€å„åœ°è¾¦äº‹è™•",
                    "type": "è¾¦äº‹è™•è³‡è¨Š",
                    "ç¸£å¸‚åˆ¥": item.get('ç¸£å¸‚åˆ¥', '')
                })
                ids.append(f"office_{uuid.uuid4()}")
                
        except Exception as e:
            logger.error(f"è¼‰å…¥å‹ä¿å±€è¾¦äº‹è™•å¤±æ•—: {e}")
        
        # 6. è¼‰å…¥é†«é™¢åå–®
        try:
            with open('å‹ä¿è³‡æ–™é›†/è¡›ç”Ÿç¦åˆ©éƒ¨è©•é‘‘åˆæ ¼ä¹‹é†«é™¢åå–®.json', 'r', encoding='utf-8') as f:
                hospitals = json.load(f)
            
            for item in hospitals:
                doc_text = f"""
é†«é™¢åç¨±ï¼š{item.get('é†«é™¢åç¨±', '')}
æ‰€åœ¨ç¸£å¸‚ï¼š{item.get('æ‰€åœ¨ç¸£å¸‚', '')}
é†«é™¢è©•é‘‘è©•é‘‘çµæœï¼š{item.get('é†«é™¢è©•é‘‘è©•é‘‘çµæœ', '')}
é†«é™¢é›»è©±ï¼š{item.get('é†«é™¢é›»è©±', '')}
åœ°å€ï¼š{item.get('åœ°å€', '')}
                """.strip()
                
                documents.append(doc_text)
                metadatas.append({
                    "source": "è¡›ç”Ÿç¦åˆ©éƒ¨è©•é‘‘åˆæ ¼ä¹‹é†«é™¢åå–®",
                    "type": "é†«é™¢è³‡è¨Š",
                    "æ‰€åœ¨ç¸£å¸‚": item.get('æ‰€åœ¨ç¸£å¸‚', ''),
                    "é†«é™¢åç¨±": item.get('é†«é™¢åç¨±', '')
                })
                ids.append(f"hospital_{uuid.uuid4()}")
                
        except Exception as e:
            logger.error(f"è¼‰å…¥é†«é™¢åå–®å¤±æ•—: {e}")
        
        # æ‰¹é‡æ·»åŠ åˆ°å‘é‡æ•¸æ“šåº«
        if documents:
            # ç”ŸæˆåµŒå…¥å‘é‡
            embeddings = embedding_model.encode(documents).tolist()
            
            # æ·»åŠ åˆ° ChromaDB
            collection.add(
                documents=documents,
                metadatas=metadatas,
                ids=ids,
                embeddings=embeddings
            )
            
            logger.info(f"æˆåŠŸè¼‰å…¥ {len(documents)} æ¢è¨˜éŒ„åˆ°å‘é‡æ•¸æ“šåº«")
            return True
        else:
            logger.warning("æ²’æœ‰æ‰¾åˆ°ä»»ä½•æ–‡æª”ä¾†è¼‰å…¥")
            return False
            
    except Exception as e:
        logger.error(f"è¼‰å…¥å‘é‡æ•¸æ“šåº«å¤±æ•—: {e}")
        return False

# åˆå§‹åŒ–æ™‚è¼‰å…¥æ‰€æœ‰è³‡æ–™é›†
load_all_datasets_to_vector_db()

# åˆå§‹åŒ– Ollama å®¢æˆ¶ç«¯
ollama_client = ollama.Client(host='http://127.0.0.1:11434')

# è«‹æ±‚æ¨¡å‹
class ChatRequest(BaseModel):
    message: str
    session_id: str = "default"

class ChatResponse(BaseModel):
    response: str
    sources: List[str]
    success: bool

def find_preset_answer(question: str) -> str:
    """æŸ¥æ‰¾é è¨­å•é¡Œçš„ç­”æ¡ˆ - å„ªå…ˆä½¿ç”¨JSONè³‡æ–™åº«"""
    question = question.strip()
    
    # 1. å„ªå…ˆä½¿ç”¨JSONè³‡æ–™åº«
    if qa_database:
        answer = search_qa_database(question)
        if answer:
            return answer
    
    # 2. å›é€€åˆ°åŸå§‹PRESET_QA
    if question in PRESET_QA:
        return PRESET_QA[question]
    
    # 3. é—œéµå­—åŒ¹é…
    for preset_q, answer in PRESET_QA.items():
        clean_question = question.replace("ï¼Ÿ", "").replace("?", "").replace("ã€‚", "")
        clean_preset = preset_q.replace("ï¼Ÿ", "").replace("?", "").replace("ã€‚", "")
        
        if any(keyword in clean_question for keyword in clean_preset.split()):
            return answer
    
    return ""

def search_vector_database(question: str, top_k: int = 3) -> List[dict]:
    """åœ¨å‘é‡æ•¸æ“šåº«ä¸­æœç´¢ç›¸é—œæ–‡æª”"""
    if not collection or not embedding_model:
        return []
    
    try:
        # ç”ŸæˆæŸ¥è©¢å‘é‡
        query_embedding = embedding_model.encode([question]).tolist()[0]
        
        # æœç´¢ç›¸ä¼¼æ–‡æª”
        results = collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k,
            include=['documents', 'metadatas', 'distances']
        )
        
        # æ ¼å¼åŒ–çµæœ
        formatted_results = []
        if results['documents'] and results['documents'][0]:
            for i, doc in enumerate(results['documents'][0]):
                formatted_results.append({
                    'document': doc,
                    'metadata': results['metadatas'][0][i] if results['metadatas'] else {},
                    'distance': results['distances'][0][i] if results['distances'] else 0
                })
        
        return formatted_results
        
    except Exception as e:
        logger.error(f"å‘é‡æ•¸æ“šåº«æœç´¢å¤±æ•—: {e}")
        return []

def search_qa_database(question: str) -> str:
    """åœ¨JSONè³‡æ–™åº«ä¸­æœç´¢ç­”æ¡ˆ"""
    if not qa_database:
        return ""
    
    clean_question = question.replace("ï¼Ÿ", "").replace("?", "").replace("ã€‚", "")
    
    # 1. ç›´æ¥åŒ¹é…
    for category, questions in qa_database["å¸¸è¦‹å•é¡Œ"].items():
        for q, answer in questions.items():
            if q == question or q == clean_question:
                return answer
    
    # 2. é—œéµè©åŒ¹é…
    for category, questions in qa_database["å¸¸è¦‹å•é¡Œ"].items():
        for q, answer in questions.items():
            clean_q = q.replace("ï¼Ÿ", "").replace("?", "").replace("ã€‚", "")
            if any(keyword in clean_question for keyword in clean_q.split()):
                return answer
    
    # 3. ä½¿ç”¨å¿«é€ŸæŸ¥è©¢é—œéµè©
    if "å¿«é€ŸæŸ¥è©¢é—œéµè©" in qa_database:
        for keyword, synonyms in qa_database["å¿«é€ŸæŸ¥è©¢é—œéµè©"].items():
            if any(syn in clean_question for syn in synonyms):
                # æ‰¾åˆ°ç›¸é—œé—œéµè©ï¼Œæœç´¢å°æ‡‰ç­”æ¡ˆ
                for category, questions in qa_database["å¸¸è¦‹å•é¡Œ"].items():
                    for q, answer in questions.items():
                        if keyword in q or any(syn in q for syn in synonyms):
                            return answer
    
    return ""

@app.get("/")
async def root():
    return {"message": "æ™ºæ…§å‹ç½ä¿éšªä¸€ç«™å¼æœå‹™ API"}

@app.get("/health")
async def health_check():
    return {"status": "healthy"}

@app.get("/api/chat/preset-questions")
async def get_preset_questions():
    """ç²å–é è¨­å•é¡Œåˆ—è¡¨"""
    questions = []
    
    # å„ªå…ˆå¾JSONè³‡æ–™åº«ç²å–
    if qa_database and "å¸¸è¦‹å•é¡Œ" in qa_database:
        for category, qa_dict in qa_database["å¸¸è¦‹å•é¡Œ"].items():
            questions.extend(list(qa_dict.keys()))
    else:
        # å›é€€åˆ°åŸå§‹PRESET_QA
        questions = list(PRESET_QA.keys())
    
    return {
        "questions": questions,
        "total": len(questions)
    }

@app.get("/api/rag/status")
async def get_rag_status():
    """ç²å–RAGç³»çµ±ç‹€æ…‹"""
    try:
        if not collection:
            return {
                "status": "error",
                "message": "ChromaDB æœªåˆå§‹åŒ–",
                "vector_db_count": 0
            }
        
        count = collection.count()
        return {
            "status": "healthy",
            "message": "RAGç³»çµ±é‹è¡Œæ­£å¸¸",
            "vector_db_count": count,
            "embedding_model": "paraphrase-multilingual-MiniLM-L12-v2",
            "collections": ["labor_insurance_knowledge"]
        }
    except Exception as e:
        return {
            "status": "error",
            "message": f"RAGç³»çµ±ç‹€æ…‹æª¢æŸ¥å¤±æ•—: {str(e)}",
            "vector_db_count": 0
        }

@app.post("/api/rag/reload")
async def reload_vector_database():
    """é‡æ–°è¼‰å…¥å‘é‡æ•¸æ“šåº«"""
    try:
        if not collection:
            return {
                "success": False,
                "message": "ChromaDB æœªåˆå§‹åŒ–"
            }
        
        # æ¸…ç©ºç¾æœ‰æ•¸æ“š
        collection.delete()
        
        # é‡æ–°è¼‰å…¥
        success = load_all_datasets_to_vector_db()
        
        if success:
            count = collection.count()
            return {
                "success": True,
                "message": f"æˆåŠŸé‡æ–°è¼‰å…¥ {count} æ¢è¨˜éŒ„",
                "record_count": count
            }
        else:
            return {
                "success": False,
                "message": "é‡æ–°è¼‰å…¥å¤±æ•—"
            }
            
    except Exception as e:
        return {
            "success": False,
            "message": f"é‡æ–°è¼‰å…¥å¤±æ•—: {str(e)}"
        }

@app.post("/api/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """RAGå¢å¼·ç‰ˆèŠå¤© API"""
    try:
        # 1. å…ˆæª¢æŸ¥æ˜¯å¦æœ‰é è¨­ç­”æ¡ˆ
        preset_answer = find_preset_answer(request.message)
        if preset_answer and preset_answer.strip():
            return ChatResponse(
                response=preset_answer,
                sources=["é è¨­çŸ¥è­˜åº«"],
                success=True
            )
        
        # 2. ä½¿ç”¨RAGç³»çµ±æœç´¢ç›¸é—œæ–‡æª”
        relevant_docs = search_vector_database(request.message, top_k=3)
        
        # 3. æ§‹å»ºåŸºæ–¼æ–‡æª”çš„æç¤ºè©
        context_text = ""
        sources = []
        
        if relevant_docs:
            for doc in relevant_docs:
                context_text += f"\nç›¸é—œè³‡è¨Šï¼š\n{doc['document']}\n"
                source_name = doc['metadata'].get('source', 'æœªçŸ¥ä¾†æº')
                if source_name not in sources:
                    sources.append(source_name)
        
        # æ§‹å»ºå®Œæ•´çš„æç¤ºè©
        prompt = f"""ä½ æ˜¯å‹ç½ä¿éšªè«®è©¢åŠ©æ‰‹ï¼Œå°ˆé–€å›ç­”å‹å·¥ä¿éšªç›¸é—œå•é¡Œã€‚è«‹æ ¹æ“šä»¥ä¸‹ç›¸é—œè³‡æ–™å›ç­”å•é¡Œã€‚

å•é¡Œï¼š{request.message}

ç›¸é—œè³‡æ–™ï¼š
{context_text}

è«‹æ ¹æ“šä»¥ä¸Šè³‡æ–™ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œæä¾›æº–ç¢ºã€å°ˆæ¥­çš„è³‡è¨Šã€‚å¦‚æœè³‡æ–™ä¸­æ²’æœ‰ç›¸é—œè³‡è¨Šï¼Œè«‹èªªæ˜ä¸¦å»ºè­°ç”¨æˆ¶è«®è©¢ç›¸é—œæ©Ÿæ§‹ã€‚å›ç­”è«‹æ§åˆ¶åœ¨200å­—ä»¥å…§ï¼š"""

        # ä½¿ç”¨ Ollama ç”Ÿæˆå›ç­”
        response = ollama_client.generate(
            model="gemma3:4b",
            prompt=prompt,
            options={
                'temperature': 0.3,  # é™ä½æº«åº¦ä»¥æé«˜æº–ç¢ºæ€§
                'top_p': 0.8,
                'max_tokens': 300,  # å¢åŠ tokenæ•¸ä»¥æ”¯æŒæ›´è©³ç´°çš„å›ç­”
            }
        )
        
        answer = response['response'].strip()
        
        # å¦‚æœæ²’æœ‰æ‰¾åˆ°ç›¸é—œæ–‡æª”ï¼Œæ·»åŠ èªªæ˜
        if not relevant_docs:
            answer += "\n\næ³¨æ„ï¼šæ­¤å•é¡Œçš„ç›¸é—œè³‡æ–™å¯èƒ½ä¸åœ¨æˆ‘å€‘çš„çŸ¥è­˜åº«ä¸­ï¼Œå»ºè­°æ‚¨ç›´æ¥è¯ç¹«å‹ä¿å±€æˆ–ç›¸é—œæ©Ÿæ§‹ç²å¾—æ›´æº–ç¢ºçš„è³‡è¨Šã€‚"
            sources = ["AI èªè¨€æ¨¡å‹"]
        else:
            sources.append("AI èªè¨€æ¨¡å‹")
        
        return ChatResponse(
            response=answer,
            sources=sources,
            success=True
        )
        
    except Exception as e:
        logger.error(f"èŠå¤©è™•ç†å¤±æ•—: {e}")
        return ChatResponse(
            response="æŠ±æ­‰ï¼Œè™•ç†æ‚¨çš„å•é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚",
            sources=[],
            success=False
        )

@app.post("/api/disability/body-part")
async def analyze_body_part_injury(request: dict):
    """æ ¹æ“šèº«é«”éƒ¨ä½å’Œå‚·å®³æè¿°åˆ†æå¯èƒ½çš„å¤±èƒ½ç­‰ç´š"""
    try:
        body_part = request.get("body_part", "")
        injury_description = request.get("injury_description", "")
        
        if not body_part or not injury_description:
            return {
                "error": "è«‹æä¾›èº«é«”éƒ¨ä½å’Œå‚·å®³æè¿°",
                "success": False
            }
        
        # æ§‹å»ºåˆ†ææç¤ºè©
        prompt = f"""ä½ æ˜¯å‹å·¥ä¿éšªå¤±èƒ½çµ¦ä»˜æ¨™æº–å°ˆå®¶ã€‚è«‹æ ¹æ“šä»¥ä¸‹è³‡è¨Šåˆ†æå¯èƒ½çš„å¤±èƒ½ç­‰ç´šï¼š

èº«é«”éƒ¨ä½ï¼š{body_part}
å‚·å®³æè¿°ï¼š{injury_description}

å‹å·¥ä¿éšªå¤±èƒ½çµ¦ä»˜æ¨™æº–åˆ†ç‚º12é¡ï¼šç²¾ç¥ã€ç¥ç¶“ã€çœ¼ã€è€³ã€é¼»ã€å£ã€èƒ¸è…¹éƒ¨è‡Ÿå™¨ã€è»€å¹¹ã€é ­è‡‰é ¸ã€çš®è†šã€ä¸Šè‚¢ã€ä¸‹è‚¢ã€‚

å¤±èƒ½ç­‰ç´š1-15ç´šå°æ‡‰çµ¦ä»˜æ—¥æ•¸ï¼š
- 1ç´šï¼šæ™®é€š1200æ—¥ï¼Œè·æ¥­1800æ—¥
- 2ç´šï¼šæ™®é€š1000æ—¥ï¼Œè·æ¥­1500æ—¥  
- 3ç´šï¼šæ™®é€š840æ—¥ï¼Œè·æ¥­1260æ—¥
- 4ç´šï¼šæ™®é€š740æ—¥ï¼Œè·æ¥­1110æ—¥
- 5ç´šï¼šæ™®é€š640æ—¥ï¼Œè·æ¥­960æ—¥
- 6ç´šï¼šæ™®é€š540æ—¥ï¼Œè·æ¥­810æ—¥
- 7ç´šï¼šæ™®é€š440æ—¥ï¼Œè·æ¥­660æ—¥
- 8ç´šï¼šæ™®é€š360æ—¥ï¼Œè·æ¥­540æ—¥
- 9ç´šï¼šæ™®é€š280æ—¥ï¼Œè·æ¥­420æ—¥
- 10ç´šï¼šæ™®é€š220æ—¥ï¼Œè·æ¥­330æ—¥
- 11ç´šï¼šæ™®é€š160æ—¥ï¼Œè·æ¥­240æ—¥
- 12ç´šï¼šæ™®é€š100æ—¥ï¼Œè·æ¥­150æ—¥
- 13ç´šï¼šæ™®é€š60æ—¥ï¼Œè·æ¥­90æ—¥
- 14ç´šï¼šæ™®é€š40æ—¥ï¼Œè·æ¥­60æ—¥
- 15ç´šï¼šæ™®é€š30æ—¥ï¼Œè·æ¥­45æ—¥

è«‹æ ¹æ“šå‚·å®³åš´é‡ç¨‹åº¦åˆ†æå¯èƒ½çš„å¤±èƒ½ç­‰ç´šï¼Œä¸¦æä¾›ç°¡æ½”èªªæ˜ã€‚

å›ç­”æ ¼å¼ï¼š
- å¯èƒ½å¤±èƒ½ç­‰ç´šï¼šXç´š
- èªªæ˜ï¼š[ç°¡æ½”èªªæ˜åŸå› ]
- çµ¦ä»˜æ—¥æ•¸ï¼šæ™®é€šå‚·ç—…Xæ—¥ï¼Œè·æ¥­å‚·ç—…Xæ—¥

è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œé™åˆ¶åœ¨100å­—ä»¥å…§ï¼š"""

        # ä½¿ç”¨ Ollama ç”Ÿæˆåˆ†æ
        response = ollama_client.generate(
            model="gemma3:4b",
            prompt=prompt,
            options={
                'temperature': 0.7,
                'top_p': 0.9,
                'max_tokens': 150,
            }
        )
        
        analysis = response['response'].strip()
        
        return {
            "body_part": body_part,
            "injury_description": injury_description,
            "analysis": analysis,
            "success": True
        }
        
    except Exception as e:
        logger.error(f"èº«é«”éƒ¨ä½åˆ†æå¤±æ•—: {e}")
        return {
            "error": "åˆ†æèº«é«”éƒ¨ä½å‚·å®³æ™‚ç™¼ç”ŸéŒ¯èª¤",
            "success": False
        }

# è¼‰å…¥å¤±èƒ½çµ¦ä»˜æ¨™æº–æ•¸æ“š
def load_disability_benefit_standards():
    """è¼‰å…¥å¤±èƒ½çµ¦ä»˜æ¨™æº–æ•¸æ“š"""
    try:
        with open('å‹ä¿è³‡æ–™é›†/å„å¤±èƒ½ç­‰ç´šä¹‹çµ¦ä»˜æ¨™æº–.json', 'r', encoding='utf-8') as f:
            standards = json.load(f)
        return standards
    except Exception as e:
        logger.error(f"è¼‰å…¥å¤±èƒ½çµ¦ä»˜æ¨™æº–å¤±æ•—: {e}")
        return None

# è¼‰å…¥å¤±èƒ½çµ¦ä»˜æ¨™æº–
disability_standards = load_disability_benefit_standards()

@app.post("/api/disability/benefit")
async def get_disability_benefit(request: dict):
    """æ ¹æ“šå¤±èƒ½ç­‰ç´šæŸ¥è©¢çµ¦ä»˜æ¨™æº–"""
    try:
        level = request.get("level")
        injury_type = request.get("injury_type", "æ™®é€šå‚·ç—…")
        
        logger.info(f"æŸ¥è©¢å¤±èƒ½çµ¦ä»˜: level={level}, injury_type={injury_type}")
        
        if not level:
            return {"error": "è«‹æä¾›å¤±èƒ½ç­‰ç´š", "success": False}
        
        if not disability_standards:
            return {"error": "å¤±èƒ½çµ¦ä»˜æ¨™æº–æ•¸æ“šè¼‰å…¥å¤±æ•—", "success": False}
        
        # å¾JSONæ•¸æ“šä¸­æŸ¥æ‰¾å°æ‡‰ç­‰ç´š
        level_data = None
        for standard in disability_standards:
            if standard["å¤±èƒ½ç­‰ç´š"] == str(level):
                level_data = standard
                break
        
        if not level_data:
            return {"error": f"ç„¡æ•ˆçš„å¤±èƒ½ç­‰ç´š: {level}", "success": False}
        
        # æå–çµ¦ä»˜æ—¥æ•¸
        ordinary_days = int(level_data["æ™®é€šå‚·ç—…å¤±èƒ½è£œåŠ©è²»çµ¦ä»˜æ¨™æº–"].replace("æ—¥", ""))
        occupational_days = int(level_data["è·æ¥­å‚·ç—…å¤±èƒ½è£œå„Ÿè²»çµ¦ä»˜æ¨™æº–"].replace("æ—¥", ""))
        
        # ç¢ºå®šå‚·ç—…é¡å‹
        if injury_type in ["è·æ¥­å‚·ç—…", "è·æ¥­ç½å®³", "è·æ¥­"]:
            benefit_type = "è·æ¥­"
            benefit_days = occupational_days
        else:
            benefit_type = "æ™®é€š"
            benefit_days = ordinary_days
        
        # æ§‹å»ºè©³ç´°èªªæ˜
        level_int = int(level)
        severity = 'è¼ƒåš´é‡' if level_int <= 5 else 'ä¸­ç­‰' if level_int <= 10 else 'è¼ƒè¼•å¾®'
        
        explanation = f"""å¤±èƒ½ç­‰ç´šç¬¬{level}ç´šçµ¦ä»˜æ¨™æº–ï¼š

çµ¦ä»˜æ—¥æ•¸ï¼š{benefit_days}æ—¥
å‚·ç—…é¡å‹ï¼š{injury_type}
çµ¦ä»˜æ¨™æº–ï¼š{benefit_type}å‚·ç—…

èªªæ˜ï¼š
â€¢ å¤±èƒ½ç­‰ç´šç¬¬{level}ç´šå±¬æ–¼{severity}çš„å¤±èƒ½ç¨‹åº¦
â€¢ çµ¦ä»˜æ—¥æ•¸ä¾å‹å·¥ä¿éšªå¤±èƒ½çµ¦ä»˜æ¨™æº–è¨ˆç®—
â€¢ è·æ¥­å‚·ç—…çµ¦ä»˜æ—¥æ•¸ç‚ºæ™®é€šå‚·ç—…çš„1.5å€
â€¢ å¯¦éš›çµ¦ä»˜é‡‘é¡éœ€ä¾æŠ•ä¿è–ªè³‡è¨ˆç®—

æ³¨æ„äº‹é …ï¼š
â€¢ éœ€ç”±å¥ä¿ç‰¹ç´„é†«é™¢å‡ºå…·å¤±èƒ½è¨ºæ–·æ›¸
â€¢ ç”³è«‹æ™‚éœ€æª¢é™„ç›¸é—œé†«ç™‚è­‰æ˜æ–‡ä»¶
â€¢ çµ¦ä»˜æ¨™æº–å¯èƒ½å› æ³•è¦ä¿®è¨‚è€Œèª¿æ•´"""
        
        return {
            "level": level,
            "injury_type": injury_type,
            "benefit_type": benefit_type,
            "benefit_days": benefit_days,
            "ordinary_days": ordinary_days,
            "occupational_days": occupational_days,
            "general_benefit": f"{ordinary_days}æ—¥",
            "occupational_benefit": f"{occupational_days}æ—¥",
            "explanation": explanation,
            "success": True
        }
        
    except Exception as e:
        logger.error(f"æŸ¥è©¢å¤±èƒ½çµ¦ä»˜å¤±æ•—: {e}")
        return {
            "error": "æŸ¥è©¢å¤±èƒ½çµ¦ä»˜æ™‚ç™¼ç”ŸéŒ¯èª¤",
            "success": False
        }

# è¼‰å…¥åœ°åœ–æ•¸æ“š
def load_map_data():
    """è¼‰å…¥åœ°åœ–ç›¸é—œæ•¸æ“š"""
    try:
        # è¼‰å…¥å‹ä¿å±€è¾¦äº‹è™•æ•¸æ“š
        with open('å‹ä¿è³‡æ–™é›†/å‹ä¿å±€å„åœ°è¾¦äº‹è™•.json', 'r', encoding='utf-8') as f:
            labor_offices = json.load(f)
        
        # è¼‰å…¥é†«é™¢æ•¸æ“šï¼ˆä½¿ç”¨å«ç¶“ç·¯åº¦çš„ç‰ˆæœ¬ï¼‰
        with open('å‹ä¿è³‡æ–™é›†/è¡›ç”Ÿç¦åˆ©éƒ¨è©•é‘‘åˆæ ¼ä¹‹é†«é™¢åå–®_å«ç¶“ç·¯åº¦.json', 'r', encoding='utf-8') as f:
            hospitals = json.load(f)
        
        return {
            "labor_offices": labor_offices,
            "hospitals": hospitals
        }
    except Exception as e:
        logger.error(f"è¼‰å…¥åœ°åœ–æ•¸æ“šå¤±æ•—: {e}")
        return None

# è¼‰å…¥åœ°åœ–æ•¸æ“š
map_data = load_map_data()

@app.get("/api/maps/cities")
async def get_cities():
    """ç²å–æ‰€æœ‰åŸå¸‚åˆ—è¡¨"""
    if not map_data:
        return {"error": "åœ°åœ–æ•¸æ“šè¼‰å…¥å¤±æ•—", "success": False}
    
    cities = set()
    for office in map_data["labor_offices"]:
        city = office["ç¸£å¸‚åˆ¥"].replace("è¾¦äº‹è™•", "").replace("å¸‚", "").replace("ç¸£", "")
        cities.add(city)
    
    return {
        "cities": sorted(list(cities)),
        "success": True
    }

@app.post("/api/maps/nearby")
async def get_nearby_locations(request: dict):
    """ç²å–é™„è¿‘ä½ç½®"""
    try:
        latitude = request.get("latitude")
        longitude = request.get("longitude")
        location_type = request.get("type", "hospital")
        radius = request.get("radius", 50)
        
        logger.info(f"æ”¶åˆ°åœ°åœ–æœç´¢è«‹æ±‚: lat={latitude}, lng={longitude}, type={location_type}, radius={radius}")
        
        if not latitude or not longitude:
            logger.error("ç¼ºå°‘ç·¯åº¦æˆ–ç¶“åº¦")
            return {"error": "è«‹æä¾›ç·¯åº¦å’Œç¶“åº¦", "success": False}
        
        if not map_data:
            logger.error("åœ°åœ–æ•¸æ“šæœªè¼‰å…¥")
            return {"error": "åœ°åœ–æ•¸æ“šè¼‰å…¥å¤±æ•—", "success": False}
        
        # è¨ˆç®—è·é›¢ä¸¦ç¯©é¸é™„è¿‘çš„é»
        nearby_locations = []
        
        if location_type == "hospital":
            import math
            
            # è¨ˆç®—çœŸå¯¦è·é›¢ï¼ˆä½¿ç”¨Haversineå…¬å¼ï¼‰
            def calculate_distance(lat1, lon1, lat2, lon2):
                R = 6371  # åœ°çƒåŠå¾‘ï¼ˆå…¬é‡Œï¼‰
                dlat = math.radians(lat2 - lat1)
                dlon = math.radians(lon2 - lon1)
                a = math.sin(dlat/2) * math.sin(dlat/2) + math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) * math.sin(dlon/2) * math.sin(dlon/2)
                c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))
                return R * c
            
            # æŒ‰é†«é™¢ç­‰ç´šåˆ†é¡
            hospital_categories = {
                "é†«å­¸ä¸­å¿ƒ": [],
                "å€åŸŸé†«é™¢": [],
                "åœ°å€é†«é™¢": [],
                "è¨ºæ‰€": []
            }
            
            for hospital in map_data["hospitals"]:
                # ä½¿ç”¨çœŸå¯¦çš„ç¶“ç·¯åº¦
                hospital_lat = hospital.get("ç·¯åº¦")
                hospital_lng = hospital.get("ç¶“åº¦")
                
                if hospital_lat is None or hospital_lng is None:
                    continue
                
                # è¨ˆç®—è·é›¢
                distance_km = calculate_distance(latitude, longitude, hospital_lat, hospital_lng)
                
                # è§£æé†«é™¢ç­‰ç´š
                level_text = hospital["é†«é™¢è©•é‘‘è©•é‘‘çµæœ"]
                if "é†«å­¸ä¸­å¿ƒ" in level_text:
                    category = "é†«å­¸ä¸­å¿ƒ"
                elif "å€åŸŸé†«é™¢" in level_text:
                    category = "å€åŸŸé†«é™¢"
                elif "åœ°å€é†«é™¢" in level_text:
                    category = "åœ°å€é†«é™¢"
                else:
                    category = "è¨ºæ‰€"
                
                # åœ¨é†«é™¢åç¨±å¾Œé¢åŠ ä¸Šç­‰ç´šæ¨™ç¤º
                hospital_name_with_level = f"{hospital['é†«é™¢åç¨±']}({category})"
                
                hospital_info = {
                    "name": hospital_name_with_level,
                    "original_name": hospital["é†«é™¢åç¨±"],  # ä¿ç•™åŸå§‹åç¨±
                    "address": hospital.get("åœ°å€", "åœ°å€ä¸è©³"),
                    "city": hospital["æ‰€åœ¨ç¸£å¸‚"],
                    "type": "hospital",
                    "phone": hospital.get("é†«é™¢é›»è©±", ""),
                    "level": level_text,
                    "category": category,
                    "latitude": hospital_lat,
                    "longitude": hospital_lng,
                    "distance": round(distance_km, 2)
                }
                
                hospital_categories[category].append(hospital_info)
            
            # æŒ‰è·é›¢æ’åºæ¯å€‹é¡åˆ¥ï¼Œä¸¦å–æœ€è¿‘çš„3å€‹
            for category, hospitals in hospital_categories.items():
                hospitals.sort(key=lambda x: x["distance"])
                nearby_locations.extend(hospitals[:3])  # æ¯é¡å–æœ€è¿‘çš„3å€‹
        elif location_type == "labor_office":
            logger.info(f"è™•ç†å‹ä¿å±€è¾¦äº‹è™•æœç´¢ï¼Œå…±æœ‰ {len(map_data['labor_offices'])} å€‹è¾¦äº‹è™•")
            # ç°¡åŒ–è·é›¢è¨ˆç®—ï¼Œç›´æ¥è¿”å›æ‰€æœ‰å‹ä¿å±€è¾¦äº‹è™•
            for office in map_data["labor_offices"]:
                office_lat = float(office["ç·¯åº¦"])
                office_lng = float(office["ç¶“åº¦"])
                
                # ç°¡å–®çš„è·é›¢è¨ˆç®—
                lat_diff = latitude - office_lat
                lng_diff = longitude - office_lng
                distance_km = ((lat_diff ** 2 + lng_diff ** 2) ** 0.5) * 111
                
                nearby_locations.append({
                    "name": office["ç¸£å¸‚åˆ¥"],
                    "address": office["è¾¦äº‹è™•åœ°å€"],
                    "city": office["ç¸£å¸‚åˆ¥"],
                    "type": "labor_office",
                    "phone": office["è¾¦äº‹è™•é›»è©±"],
                    "service_hours": office["æ«ƒå°æœå‹™æ™‚é–“"],
                    "phone_hours": office["é›»è©±æœå‹™æ™‚é–“"],
                    "latitude": office_lat,
                    "longitude": office_lng,
                    "distance": distance_km
                })
            
            logger.info(f"å‹ä¿å±€è¾¦äº‹è™•è™•ç†å®Œæˆï¼Œè¿”å› {len(nearby_locations)} å€‹ä½ç½®")
        
        # æŒ‰è·é›¢æ’åº
        nearby_locations.sort(key=lambda x: x.get("distance", 0))
        
        # æ ¹æ“šé¡å‹é™åˆ¶è¿”å›æ•¸é‡
        if location_type == "hospital":
            # é†«é™¢æŒ‰ç­‰ç´šåˆ†é¡è¿”å›ï¼ˆæ¯é¡3å€‹ï¼Œå…±12å€‹ï¼‰
            result_locations = nearby_locations[:12]  # æœ€å¤š12å€‹ï¼ˆ4é¡Ã—3å€‹ï¼‰
            
            # çµ±è¨ˆå„é¡åˆ¥æ•¸é‡
            category_counts = {}
            for location in result_locations:
                category = location.get("category", "æœªçŸ¥")
                category_counts[category] = category_counts.get(category, 0) + 1
            
            result_message = f"æ‰¾åˆ°æœ€è¿‘çš„é†«é™¢ï¼šé†«å­¸ä¸­å¿ƒ{category_counts.get('é†«å­¸ä¸­å¿ƒ', 0)}å®¶ã€å€åŸŸé†«é™¢{category_counts.get('å€åŸŸé†«é™¢', 0)}å®¶ã€åœ°å€é†«é™¢{category_counts.get('åœ°å€é†«é™¢', 0)}å®¶ã€è¨ºæ‰€{category_counts.get('è¨ºæ‰€', 0)}å®¶"
        else:
            # å‹ä¿å±€è¾¦äº‹è™•è¿”å›å‰20å€‹
            result_locations = nearby_locations[:20]
            result_message = f"æ‰¾åˆ° {len(result_locations)} å€‹å‹ä¿å±€è¾¦äº‹è™•"
        
        return {
            "locations": result_locations,
            "total": len(nearby_locations),
            "message": result_message,
            "success": True
        }
        
    except Exception as e:
        logger.error(f"ç²å–é™„è¿‘ä½ç½®å¤±æ•—: {e}")
        return {"error": "ç²å–é™„è¿‘ä½ç½®å¤±æ•—", "success": False}

@app.get("/api/maps/city/{city_name}")
async def get_locations_by_city(city_name: str, type: str = "hospital"):
    """æ ¹æ“šåŸå¸‚ç²å–ä½ç½®"""
    try:
        if not map_data:
            return {"error": "åœ°åœ–æ•¸æ“šè¼‰å…¥å¤±æ•—", "success": False}
        
        locations = []
        
        if type == "hospital":
            for hospital in map_data["hospitals"]:
                if city_name in hospital["æ‰€åœ¨ç¸£å¸‚"]:
                    locations.append({
                        "name": hospital["é†«é™¢åç¨±"],
                        "address": hospital.get("åœ°å€", "åœ°å€ä¸è©³"),
                        "city": hospital["æ‰€åœ¨ç¸£å¸‚"],
                        "type": "hospital",
                        "phone": hospital.get("é›»è©±", ""),
                        "level": hospital["é†«é™¢è©•é‘‘è©•é‘‘çµæœ"],
                        "latitude": 25.0,  # æš«æ™‚ä½¿ç”¨é è¨­å€¼
                        "longitude": 121.5  # æš«æ™‚ä½¿ç”¨é è¨­å€¼
                    })
        elif type == "labor_office":
            for office in map_data["labor_offices"]:
                if city_name in office["ç¸£å¸‚åˆ¥"]:
                    locations.append({
                        "name": office["ç¸£å¸‚åˆ¥"],
                        "address": office["è¾¦äº‹è™•åœ°å€"],
                        "city": office["ç¸£å¸‚åˆ¥"],
                        "type": "labor_office",
                        "phone": office["è¾¦äº‹è™•é›»è©±"],
                        "service_hours": office["æ«ƒå°æœå‹™æ™‚é–“"],
                        "phone_hours": office["é›»è©±æœå‹™æ™‚é–“"],
                        "latitude": float(office["ç·¯åº¦"]),
                        "longitude": float(office["ç¶“åº¦"])
                    })
        
        return {
            "locations": locations,
            "city": city_name,
            "type": type,
            "success": True
        }
        
    except Exception as e:
        logger.error(f"ç²å–åŸå¸‚ä½ç½®å¤±æ•—: {e}")
        return {"error": "ç²å–åŸå¸‚ä½ç½®å¤±æ•—", "success": False}

if __name__ == "__main__":
    import uvicorn
    print("ğŸ¥ å•Ÿå‹•æ™ºæ…§å‹ç½ä¿éšªæœå‹™...")
    print("ğŸŒ API æœå‹™: http://localhost:8000")
    print("ğŸŒ API æœå‹™: http://127.0.0.1:8000")
    print("ğŸ“– API æ–‡æª”: http://localhost:8000/docs")
    uvicorn.run(app, host="0.0.0.0", port=8000, log_level="info")
